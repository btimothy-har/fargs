{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: E501\n",
    "\n",
    "%pip install llama-index-embeddings-openai llama-index-core llama-index-graph-stores-neo4j git+https://github.com/btimothy-har/fargs.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "# You can define your own claim and entity types. Generally, this is an effective way to constrain the LLM to look at specific domains of knowledge.\n",
    "\n",
    "class EntityTypes(Enum):\n",
    "    PERSON = \"person\"\n",
    "    ORGANIZATION = \"organization\"\n",
    "    INDUSTRY = \"industry\"\n",
    "    LOCATION = \"location\"\n",
    "    LANGUAGE = \"language\"\n",
    "    CURRENCY = \"currency\"\n",
    "    GEOPOLITICAL_ENTITY = \"geopolitical_entity\"\n",
    "    NORP = \"nationality_or_religious_or_political_group\"\n",
    "    POSITION = \"position\"\n",
    "    LEGAL = \"legal_documents_or_laws_or_treaties\"\n",
    "    ART = \"work_of_art\"\n",
    "    PRODUCT_OR_SERVICE = \"product_or_service\"\n",
    "    EVENT = \"event\"\n",
    "    INFRASTRUCTURE = \"infrastructure\"\n",
    "\n",
    "class ClaimTypes(Enum):\n",
    "    FACT = \"fact\"\n",
    "    OPINION = \"opinion\"\n",
    "    PREDICTION = \"prediction\"\n",
    "    HYPOTHESIS = \"hypothesis\"\n",
    "    DENIAL = \"denial\"\n",
    "    CONFIRMATION = \"confirmation\"\n",
    "    ACCUSATION = \"accusation\"\n",
    "    PROMISE = \"promise\"\n",
    "    WARNING = \"warning\"\n",
    "    ANNOUNCEMENT = \"announcement\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from llama_index.core.embeddings import OpenAIEmbedding\n",
    "from llama_index.core.embeddings import OpenAIEmbeddingMode\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "\n",
    "# If needed, define your own embeddings and splitter strategy. Fargs defaults to using a TokenTextSplitter with chunk_size 1024 and chunk_overlap 256.\n",
    "# In this example, we use Neo4j as a graph store, which is needed if you want to use embeddings in your Graph.\n",
    "\n",
    "embeddings = OpenAIEmbedding(\n",
    "    mode=OpenAIEmbeddingMode.TEXT_SEARCH_MODE,\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=1536,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=2,\n",
    "    embed_model=embeddings,\n",
    "    breakpoint_percentile_threshold=95,\n",
    ")\n",
    "\n",
    "graph_store = Neo4jPropertyGraphStore(\n",
    "    username=\"neo4j\",\n",
    "    password=\"neo4j\",\n",
    "    url=\"bolt://localhost:7687\",\n",
    "    refresh_schema=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from llama_index.core.schema import Document\n",
    "\n",
    "from fargs import Fargs\n",
    "\n",
    "fargs = Fargs(\n",
    "    project_name=\"my_graph_project\",\n",
    "    pre_split_strategy=splitter,\n",
    "    embedding_strategy=embeddings,\n",
    "    graph_store=graph_store,\n",
    "    extraction_llm_model={\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"temperature\": 0,\n",
    "    },\n",
    "    summarization_llm_model={\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"temperature\": 0,\n",
    "    },\n",
    "    entity_types=EntityTypes,\n",
    "    claim_types=ClaimTypes,\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    Document(text=\"Hello, world!\"),\n",
    "]\n",
    "\n",
    "asyncio.run(fargs.ingest(documents))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
